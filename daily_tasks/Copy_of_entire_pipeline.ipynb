{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M_2BT5e72zk",
        "outputId": "dfec0b14-96dc-491e-8fca-588bbb761f7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns in dataset: Index(['Employee_ID', 'Employee_Name', 'Age', 'Country', 'Department',\n",
            "       'Position', 'Salary', 'Joining_Date'],\n",
            "      dtype='object')\n",
            "BEFORE vs AFTER QUERY PREPROCESSING\n",
            "\n",
            "1. Before : SHOW me emp in HR dept under Analyst\n",
            "   After  : get employee in hr department under analyst\n",
            "\n",
            "2. Before : SHOW me emp in Marketing dept under Executive\n",
            "   After  : get employee in marketing department under executive\n",
            "\n",
            "3. Before : SHOW me emp in Finance dept under Developer\n",
            "   After  : get employee in finance department under developer\n",
            "\n",
            "4. Before : SHOW me emp in Support dept under Analyst\n",
            "   After  : get employee in support department under analyst\n",
            "\n",
            "5. Before : SHOW me emp in Support dept under Consultant\n",
            "   After  : get employee in support department under consultant\n",
            "\n",
            "6. Before : SHOW me emp in HR dept under Executive\n",
            "   After  : get employee in hr department under executive\n",
            "\n",
            "7. Before : SHOW me emp in Finance dept under Assistant\n",
            "   After  : get employee in finance department under assistant\n",
            "\n",
            "8. Before : SHOW me emp in Finance dept under Manager\n",
            "   After  : get employee in finance department under manager\n",
            "\n",
            "9. Before : SHOW me emp in Marketing dept under Developer\n",
            "   After  : get employee in marketing department under developer\n",
            "\n",
            "10. Before : SHOW me emp in Sales dept under Manager\n",
            "   After  : get employee in sales department under manager\n",
            "\n",
            "11. Before : SHOW me emp in Support dept under Analyst\n",
            "   After  : get employee in support department under analyst\n",
            "\n",
            "12. Before : SHOW me emp in HR dept under Consultant\n",
            "   After  : get employee in hr department under consultant\n",
            "\n",
            "13. Before : SHOW me emp in Sales dept under Assistant\n",
            "   After  : get employee in sales department under assistant\n",
            "\n",
            "14. Before : SHOW me emp in Marketing dept under Executive\n",
            "   After  : get employee in marketing department under executive\n",
            "\n",
            "15. Before : SHOW me emp in Sales dept under Assistant\n",
            "   After  : get employee in sales department under assistant\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#step-1)Input sanitization\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv(\"/content/employee_records.csv\")\n",
        "print(\"Columns in dataset:\", df.columns)\n",
        "df['query'] = df.apply(lambda x: f\"SHOW me emp in {x['Department']} dept under {x['Position']}\", axis=1)\n",
        "#Normalization function\n",
        "def normalize_query(query):\n",
        "    \"\"\"\n",
        "    Normalize queries by:\n",
        "    - Lowercasing\n",
        "    - Removing punctuation\n",
        "    - Rewriting common abbreviations / synonyms\n",
        "    - Removing extra spaces\n",
        "    \"\"\"\n",
        "    query = query.lower()\n",
        "    query = re.sub(r'[^a-z0-9\\s]', '', query)\n",
        "    # Replace common abbreviations / synonyms\n",
        "    replacements = {\n",
        "        'emp': 'employee',\n",
        "        'dept': 'department',\n",
        "        'show me': 'get',\n",
        "        'list of': 'get',\n",
        "        'give me': 'get'\n",
        "    }\n",
        "    for k, v in replacements.items():\n",
        "        query = query.replace(k, v)\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()    # remove extra spaces\n",
        "    return query\n",
        "\n",
        "# Apply normalization\n",
        "df['normalized_query'] = df['query'].apply(normalize_query)\n",
        "\n",
        "# Display Before vs After (first 15 queries)\n",
        "print(\"BEFORE vs AFTER QUERY PREPROCESSING\\n\")\n",
        "for i, row in enumerate(df.head(15).itertuples(), start=1):\n",
        "    print(f\"{i}. Before : {row.query}\")\n",
        "    print(f\"   After  : {row.normalized_query}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEDN_JtB8KV6",
        "outputId": "96ea808d-cbad-4b94-f840-144ec0937a98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QUERY | NORMALIZED | ROLE | PERMISSIONS\n",
            "\n",
            "1. Query      : Show me emp in HR dept under Analyst\n",
            "   Normalized : get employee in hr department under analyst\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "2. Query      : Show me emp in Marketing dept under Executive\n",
            "   Normalized : get employee in marketing department under executive\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "3. Query      : Show me emp in Finance dept under Developer\n",
            "   Normalized : get employee in finance department under developer\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "4. Query      : Show me emp in Support dept under Analyst\n",
            "   Normalized : get employee in support department under analyst\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "5. Query      : Show me emp in Support dept under Consultant\n",
            "   Normalized : get employee in support department under consultant\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "6. Query      : Show me emp in HR dept under Executive\n",
            "   Normalized : get employee in hr department under executive\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "7. Query      : Show me emp in Finance dept under Assistant\n",
            "   Normalized : get employee in finance department under assistant\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "8. Query      : Show me emp in Finance dept under Manager\n",
            "   Normalized : get employee in finance department under manager\n",
            "   Role       : Manager\n",
            "   Permissions: {'view', 'edit'}\n",
            "\n",
            "9. Query      : Show me emp in Marketing dept under Developer\n",
            "   Normalized : get employee in marketing department under developer\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "10. Query      : Show me emp in Sales dept under Manager\n",
            "   Normalized : get employee in sales department under manager\n",
            "   Role       : Manager\n",
            "   Permissions: {'view', 'edit'}\n",
            "\n",
            "11. Query      : Show me emp in Support dept under Analyst\n",
            "   Normalized : get employee in support department under analyst\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "12. Query      : Show me emp in HR dept under Consultant\n",
            "   Normalized : get employee in hr department under consultant\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "13. Query      : Show me emp in Sales dept under Assistant\n",
            "   Normalized : get employee in sales department under assistant\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "14. Query      : Show me emp in Marketing dept under Executive\n",
            "   Normalized : get employee in marketing department under executive\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n",
            "15. Query      : Show me emp in Sales dept under Assistant\n",
            "   Normalized : get employee in sales department under assistant\n",
            "   Role       : Employee\n",
            "   Permissions: {'view'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Step-2)RBAC role expansion\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/employee_records.csv\")\n",
        "import re\n",
        "def normalize_query(query):\n",
        "    query = query.lower()\n",
        "    query = re.sub(r'[^a-z0-9\\s]', '', query)\n",
        "    replacements = {\n",
        "        'emp': 'employee',\n",
        "        'dept': 'department',\n",
        "        'show me': 'get',\n",
        "        'list of': 'get',\n",
        "        'give me': 'get'\n",
        "    }\n",
        "    for k, v in replacements.items():\n",
        "        query = query.replace(k, v)\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()\n",
        "    return query\n",
        "\n",
        "df['query'] = df.apply(lambda x: f\"Show me emp in {x['Department']} dept under {x['Position']}\", axis=1)\n",
        "df['normalized_query'] = df['query'].apply(normalize_query)\n",
        "\n",
        "#  Define RBAC roles, permissions, and inheritance\n",
        "roles = {\n",
        "    \"Admin\": {\"permissions\": [\"view\", \"edit\", \"delete\"], \"inherits\": []},\n",
        "    \"HR\": {\"permissions\": [\"view\", \"edit\"], \"inherits\": [\"Employee\"]},\n",
        "    \"Manager\": {\"permissions\": [\"view\", \"edit\"], \"inherits\": [\"Employee\"]},\n",
        "    \"Employee\": {\"permissions\": [\"view\"], \"inherits\": []}\n",
        "}\n",
        "\n",
        "# Function to get permissions including inheritance\n",
        "def get_permissions(role_name):\n",
        "    role = roles.get(role_name, {})\n",
        "    perms = set(role.get(\"permissions\", []))\n",
        "    for parent in role.get(\"inherits\", []):\n",
        "        perms.update(get_permissions(parent))\n",
        "    return perms\n",
        "\n",
        "#  Assign RBAC roles based on Position\n",
        "def map_role(position):\n",
        "    position = position.lower()\n",
        "    if \"admin\" in position:\n",
        "        return \"Admin\"\n",
        "    elif \"hr\" in position:\n",
        "        return \"HR\"\n",
        "    elif \"manager\" in position or \"lead\" in position:\n",
        "        return \"Manager\"\n",
        "    else:\n",
        "        return \"Employee\"\n",
        "\n",
        "df['role'] = df['Position'].apply(map_role)\n",
        "df['permissions'] = df['role'].apply(get_permissions)\n",
        "\n",
        "# Display example queries and RBAC permissions\n",
        "print(\"QUERY | NORMALIZED | ROLE | PERMISSIONS\\n\")\n",
        "for i, row in enumerate(df.head(15).itertuples(), start=1):\n",
        "    print(f\"{i}. Query      : {row.query}\")\n",
        "    print(f\"   Normalized : {row.normalized_query}\")\n",
        "    print(f\"   Role       : {row.role}\")\n",
        "    print(f\"   Permissions: {row.permissions}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38DiaDK48kOL",
        "outputId": "f8082abc-a55f-40f9-db2d-a357bc07c826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USER ROLE: Employee\n",
            "ORIGINAL QUERY: Show me information for employee Daniel Taylor\n",
            "NORMALIZED QUERY: get information for employee daniel taylor\n",
            "FILTERED CHUNKS (rows visible to user):\n",
            "      Employee_ID  Employee_Name  Age Country   Department   Position  \\\n",
            "0              1  Daniel Taylor   25      UK           HR    Analyst   \n",
            "63            64  Daniel Taylor   40   Japan      Support  Executive   \n",
            "190          191  Daniel Taylor   47   India    Marketing    Analyst   \n",
            "197          198  Daniel Taylor   28  Canada      Support  Executive   \n",
            "351          352  Daniel Taylor   52  Canada  Engineering  Executive   \n",
            "\n",
            "        Salary Joining_Date                                            query  \\\n",
            "0    142278.32   2023-06-04             Show me emp in HR dept under Analyst   \n",
            "63    40581.90   2015-08-23      Show me emp in Support dept under Executive   \n",
            "190  130916.79   2024-04-25      Show me emp in Marketing dept under Analyst   \n",
            "197   41049.89   2019-11-26      Show me emp in Support dept under Executive   \n",
            "351   65652.39   2023-11-13  Show me emp in Engineering dept under Executive   \n",
            "\n",
            "                                      normalized_query      role permissions  \n",
            "0          get employee in hr department under analyst  Employee      {view}  \n",
            "63   get employee in support department under execu...  Employee      {view}  \n",
            "190  get employee in marketing department under ana...  Employee      {view}  \n",
            "197  get employee in support department under execu...  Employee      {view}  \n",
            "351  get employee in engineering department under e...  Employee      {view}  \n",
            "\n",
            "--- Comparison with Original Example Query ---\n",
            "ORIGINAL QUERY (from df column): Show me emp in HR dept under Analyst\n",
            "NORMALIZED QUERY (from df column): get employee in hr department under analyst\n",
            "FILTERED CHUNKS (rows visible to user with original query):\n",
            " Empty DataFrame\n",
            "Columns: [Employee_ID, Employee_Name, Age, Country, Department, Position, Salary, Joining_Date, query, normalized_query, role, permissions]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "#RBAC filtering chunks\n",
        "import pandas as pd\n",
        "import re\n",
        "df = pd.read_csv(\"/content/employee_records.csv\")\n",
        "def normalize_query(query):\n",
        "    query = query.lower()\n",
        "    query = re.sub(r'[^a-z0-9\\s]', '', query)\n",
        "    query = query.replace('show me', 'get')\n",
        "    query = query.replace('list of', 'get')\n",
        "    query = query.replace('give me', 'get')\n",
        "\n",
        "    # Then word replacements with word boundaries\n",
        "    query = re.sub(r'\\bemp\\b', 'employee', query)\n",
        "    query = re.sub(r'\\bdept\\b', 'department', query)\n",
        "\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()\n",
        "    return query\n",
        "df['query'] = df.apply(lambda x: f\"Show me emp in {x['Department']} dept under {x['Position']}\", axis=1)\n",
        "df['normalized_query'] = df['query'].apply(normalize_query)\n",
        "\n",
        "#  RBAC roles and permissions\n",
        "roles = {\n",
        "    \"Admin\": {\"permissions\": [\"view\", \"edit\", \"delete\"], \"inherits\": []},\n",
        "    \"HR\": {\"permissions\": [\"view\", \"edit\"], \"inherits\": [\"Employee\"]},\n",
        "    \"Manager\": {\"permissions\": [\"view\", \"edit\"], \"inherits\": [\"Employee\"]},\n",
        "    \"Employee\": {\"permissions\": [\"view\"], \"inherits\": []}\n",
        "}\n",
        "\n",
        "def get_permissions(role_name):\n",
        "    role = roles.get(role_name, {})\n",
        "    perms = set(role.get(\"permissions\", []))\n",
        "    for parent in role.get(\"inherits\", []):\n",
        "        perms.update(get_permissions(parent))\n",
        "    return perms\n",
        "\n",
        "def map_role(position):\n",
        "    position = position.lower()\n",
        "    if \"admin\" in position:\n",
        "        return \"Admin\"\n",
        "    elif \"hr\" in position:\n",
        "        return \"HR\"\n",
        "    elif \"manager\" in position or \"lead\" in position:\n",
        "        return \"Manager\"\n",
        "    else:\n",
        "        return \"Employee\"\n",
        "\n",
        "df['role'] = df['Position'].apply(map_role)\n",
        "df['permissions'] = df['role'].apply(get_permissions)\n",
        "\n",
        "# RBAC filtering function\n",
        "def rbac_filter(user_role, normalized_query, dataset):\n",
        "    \"\"\"\n",
        "    Returns only the rows (chunks) that the user's role is allowed to see.\n",
        "    Example: Employee can see only their own department, Manager can see their team, Admin can see all.\n",
        "    \"\"\"\n",
        "    # Admin can see all\n",
        "    if user_role == \"Admin\":\n",
        "        return dataset\n",
        "\n",
        "    # Manager can see rows in their department\n",
        "    if user_role == \"Manager\":\n",
        "        # extract department from query if present\n",
        "        dept_match = re.search(r\"department (\\w+)\", normalized_query)\n",
        "        if dept_match:\n",
        "            dept = dept_match.group(1).upper()\n",
        "            return dataset[dataset['Department'].str.upper() == dept]\n",
        "        else:\n",
        "            return dataset\n",
        "\n",
        "    # HR can see all employees\n",
        "    if user_role == \"HR\":\n",
        "        return dataset\n",
        "\n",
        "    # Employee can see only their own record\n",
        "    if user_role == \"Employee\":\n",
        "        # if employee name is mentioned in query\n",
        "        # Modified regex to capture full name (e.g., 'Daniel Taylor' instead of just 'Daniel')\n",
        "        name_match = re.search(r\"employee\\s+(.+)\", normalized_query)\n",
        "        if name_match:\n",
        "            name = name_match.group(1).lower()\n",
        "            # Assuming 'Employee_Name' is the column containing employee names\n",
        "            return dataset[dataset['Employee_Name'].str.lower() == name]\n",
        "        else:\n",
        "            # fallback: no rows\n",
        "            return pd.DataFrame(columns=dataset.columns)\n",
        "\n",
        "# Example usage for user_index = 0 (Daniel Taylor, Employee Role)\n",
        "user_index = 0\n",
        "user_role = df.loc[user_index, 'role']\n",
        "employee_name_for_test = df.loc[user_index, 'Employee_Name']\n",
        "query_for_demo = f\"Show me information for employee {employee_name_for_test}\"\n",
        "normalized_query_for_demo = normalize_query(query_for_demo)\n",
        "query = query_for_demo\n",
        "normalized_query = normalized_query_for_demo\n",
        "filtered_chunks = rbac_filter(user_role, normalized_query, df)\n",
        "print(f\"USER ROLE: {user_role}\")\n",
        "print(f\"ORIGINAL QUERY: {query}\")\n",
        "print(f\"NORMALIZED QUERY: {normalized_query}\")\n",
        "print(f\"FILTERED CHUNKS (rows visible to user):\\n\", filtered_chunks.head())\n",
        "print(\"\\n--- Comparison with Original Example Query ---\")\n",
        "original_query_text = df.loc[user_index, 'query']\n",
        "original_normalized_query_text = df.loc[user_index, 'normalized_query']\n",
        "original_filtered_chunks = rbac_filter(user_role, original_normalized_query_text, df)\n",
        "print(f\"ORIGINAL QUERY (from df column): {original_query_text}\")\n",
        "print(f\"NORMALIZED QUERY (from df column): {original_normalized_query_text}\")\n",
        "print(f\"FILTERED CHUNKS (rows visible to user with original query):\\n\", original_filtered_chunks.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TAMa-lHBn6s",
        "outputId": "57777e1d-dc99-47d5-9824-8686c446d736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top Candidate Chunks:\n",
            "\n",
            "      Employee_Name   Department    Position  similarity\n",
            "16     Lily Jackson    Marketing   Assistant         0.0\n",
            "17  Daniel Anderson  Engineering  Consultant         0.0\n",
            "18      Ethan Davis           HR  Consultant         0.0\n",
            "19   Lily Hernandez      Support     Analyst         0.0\n",
            "20     Sophia Brown      Finance  Consultant         0.0\n"
          ]
        }
      ],
      "source": [
        "#step-4)KNN brute force candidate\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "def rbac_filter(user_role, normalized_query, dataset):\n",
        "    \"\"\"\n",
        "    Relaxed RBAC filtering for testing KNN.\n",
        "    Admin/HR see all.\n",
        "    Manager/Employee see all for demo purposes\n",
        "    \"\"\"\n",
        "    if user_role in [\"Admin\", \"HR\", \"Manager\", \"Employee\"]:\n",
        "        return dataset.copy()\n",
        "    else:\n",
        "        return pd.DataFrame(columns=dataset.columns)\n",
        "\n",
        "def knn_candidates(user_role, normalized_query, dataset, K=5):\n",
        "    \"\"\"\n",
        "    Returns top K candidate chunks based on query similarity after RBAC filtering.\n",
        "    \"\"\"\n",
        "    filtered_chunks = rbac_filter(user_role, normalized_query, dataset)\n",
        "\n",
        "    if filtered_chunks.empty:\n",
        "        print(\"No chunks available for this user based on RBAC.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Prepare text for TF-IDF (Position + Department)\n",
        "    filtered_chunks['text'] = filtered_chunks['Position'].astype(str) + \" \" + filtered_chunks['Department'].astype(str)\n",
        "    corpus = filtered_chunks['text'].tolist()\n",
        "\n",
        "    # TF-IDF vectorization\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    chunk_vectors = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    # Vectorize normalized query\n",
        "    query_vector = vectorizer.transform([normalized_query])\n",
        "\n",
        "    # Cosine similarity (brute force)\n",
        "    similarities = cosine_similarity(query_vector, chunk_vectors).flatten()\n",
        "\n",
        "    # Get top K candidates\n",
        "    top_k_indices = similarities.argsort()[::-1][:K]\n",
        "\n",
        "    top_candidates = filtered_chunks.iloc[top_k_indices].copy()\n",
        "    top_candidates['similarity'] = similarities[top_k_indices]\n",
        "\n",
        "    return top_candidates\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/employee_records.csv\")\n",
        "\n",
        "# Example user role and query\n",
        "user_role = \"Admin\"\n",
        "normalized_query = \"get employee department CSE\"\n",
        "\n",
        "# Get top 5 candidates\n",
        "top_candidates = knn_candidates(user_role, normalized_query, df, K=5)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nTop Candidate Chunks:\\n\")\n",
        "print(top_candidates[['Employee_Name', 'Department', 'Position', 'similarity']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7veT4iYCOwE",
        "outputId": "d717b247-2ff4-4b61-8613-73c2aba39c80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top Candidate Chunks:\n",
            "\n",
            "         Employee_Name Department Position  similarity\n",
            "4987   Mason Hernandez         HR  Analyst         1.0\n",
            "23997       Lily Brown         HR  Analyst         1.0\n",
            "23994       Lily Brown         HR  Analyst         1.0\n",
            "23993      Emma Thomas         HR  Analyst         1.0\n",
            "2716    Daniel Jackson         HR  Analyst         1.0\n"
          ]
        }
      ],
      "source": [
        "#step-5)merging query results along with variance\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "\n",
        "\n",
        "def rbac_filter(user_role, normalized_query, dataset):\n",
        "    \"\"\"\n",
        "    Relaxed RBAC filter: all roles see all rows for testing.\n",
        "    \"\"\"\n",
        "    return dataset.copy()\n",
        "\n",
        "\n",
        "def knn_candidates(user_role, normalized_query, dataset, K=5):\n",
        "    \"\"\"\n",
        "    Returns top K candidate chunks using TF-IDF similarity.\n",
        "    Extracts only relevant keywords from query that exist in dataset columns.\n",
        "    \"\"\"\n",
        "    # RBAC filtering\n",
        "    filtered_chunks = rbac_filter(user_role, normalized_query, dataset)\n",
        "    if filtered_chunks.empty:\n",
        "        print(\"No chunks available for this user based on RBAC.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    filtered_chunks = filtered_chunks.copy()\n",
        "\n",
        "    # Combine text columns for TF-IDF\n",
        "    filtered_chunks['text'] = filtered_chunks['Position'].astype(str) + \" \" + filtered_chunks['Department'].astype(str)\n",
        "    corpus = filtered_chunks['text'].tolist()\n",
        "\n",
        "    # Extract keywords from query that exist in dataset\n",
        "    keywords = []\n",
        "    for col in ['Position', 'Department']:\n",
        "        for value in dataset[col].unique():\n",
        "            if str(value).lower() in normalized_query.lower():\n",
        "                keywords.append(str(value))\n",
        "    # Use only keywords from query for vectorization\n",
        "    query_for_tfidf = \" \".join(keywords) if keywords else normalized_query\n",
        "\n",
        "    # TF-IDF vectorization\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
        "    chunk_vectors = vectorizer.fit_transform(corpus)\n",
        "    query_vector = vectorizer.transform([query_for_tfidf])\n",
        "\n",
        "    # Cosine similarity\n",
        "    similarities = cosine_similarity(query_vector, chunk_vectors).flatten()\n",
        "\n",
        "    # Top K candidates\n",
        "    top_k_indices = similarities.argsort()[::-1][:K]\n",
        "    top_candidates = filtered_chunks.iloc[top_k_indices].copy()\n",
        "    top_candidates['similarity'] = similarities[top_k_indices]\n",
        "\n",
        "    return top_candidates\n",
        "df = pd.read_csv(\"/content/employee_records.csv\")\n",
        "\n",
        "# Example user role and normalized query\n",
        "user_role = \"Employee\"\n",
        "normalized_query = \"get employee in hr department under analyst\"\n",
        "\n",
        "top_candidates = knn_candidates(user_role, normalized_query, df, K=5)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nTop Candidate Chunks:\\n\")\n",
        "print(top_candidates[['Employee_Name', 'Department', 'Position', 'similarity']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkQNd3PhDALK",
        "outputId": "d0418d98-f9c0-47b5-c699-165459189555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Merged & Ranked Results:\n",
            "\n",
            "   rank    Employee_Name Department Position  mean  var\n",
            "0     1   Daniel Jackson         HR  Analyst   1.0  0.0\n",
            "1     2      Emma Thomas         HR  Analyst   1.0  0.0\n",
            "2     3       Lily Brown         HR  Analyst   1.0  0.0\n",
            "3     4  Mason Hernandez         HR  Analyst   1.0  0.0\n"
          ]
        }
      ],
      "source": [
        "#step-6)deduplication\n",
        "import pandas as pd\n",
        "results1 = top_candidates.copy()\n",
        "results2 = top_candidates.sample(frac=1, random_state=42)\n",
        "results3 = top_candidates.sample(frac=1, random_state=24)\n",
        "merged = pd.concat([results1, results2, results3], ignore_index=True)\n",
        "# If a candidate appears multiple times, calculate variance of similarity scores\n",
        "variance_df = merged.groupby(['Employee_Name', 'Department', 'Position'])['similarity'].agg(['mean', 'var']).reset_index()\n",
        "\n",
        "# Fill NaN variance (if only one occurrence) with 0\n",
        "variance_df['var'] = variance_df['var'].fillna(0)\n",
        "# Ranking\n",
        "\n",
        "# Rank by mean similarity descending, then by lowest variance (more consistent scores first)\n",
        "variance_df['rank'] = variance_df.sort_values(['mean', 'var'], ascending=[False, True]).reset_index().index + 1\n",
        "\n",
        "# =========================\n",
        "# Display Final Ranked Results\n",
        "# =========================\n",
        "final_ranked = variance_df.sort_values('rank')\n",
        "print(\"\\nFinal Merged & Ranked Results:\\n\")\n",
        "print(final_ranked[['rank', 'Employee_Name', 'Department', 'Position', 'mean', 'var']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA6nif0TDyhK",
        "outputId": "156e84ca-8dd3-448b-f8eb-b2e396b49c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Deduplicated & Ranked Results:\n",
            "\n",
            "   final_rank    Employee_Name Department Position  mean  var\n",
            "0           1   Daniel Jackson         HR  Analyst   1.0  0.0\n",
            "1           2      Emma Thomas         HR  Analyst   1.0  0.0\n",
            "2           3       Lily Brown         HR  Analyst   1.0  0.0\n",
            "3           4  Mason Hernandez         HR  Analyst   1.0  0.0\n"
          ]
        }
      ],
      "source": [
        "#step-7)Thresholding\n",
        "import pandas as pd\n",
        "deduplicated = final_ranked.drop_duplicates(subset=['Employee_Name', 'Department', 'Position'], keep='first')\n",
        "\n",
        "\n",
        "deduplicated['final_rank'] = range(1, len(deduplicated) + 1)\n",
        "\n",
        "\n",
        "print(\"\\nFinal Deduplicated & Ranked Results:\\n\")\n",
        "print(deduplicated[['final_rank', 'Employee_Name', 'Department', 'Position', 'mean', 'var']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GggwIgVoEM23",
        "outputId": "7fbd2b55-5550-4db4-9659-ad455a943444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Results after Thresholding:\n",
            "\n",
            "   final_rank    Employee_Name Department Position  mean  var\n",
            "0           1   Daniel Jackson         HR  Analyst   1.0  0.0\n",
            "1           2      Emma Thomas         HR  Analyst   1.0  0.0\n",
            "2           3       Lily Brown         HR  Analyst   1.0  0.0\n",
            "3           4  Mason Hernandez         HR  Analyst   1.0  0.0\n"
          ]
        }
      ],
      "source": [
        "#step-8)combined pipeline function\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "SIMILARITY_THRESHOLD = 0.2\n",
        "\n",
        "\n",
        "thresholded_results = deduplicated[deduplicated['mean'] >= SIMILARITY_THRESHOLD].copy()\n",
        "\n",
        "\n",
        "thresholded_results['final_rank'] = range(1, len(thresholded_results) + 1)\n",
        "\n",
        "\n",
        "print(\"\\nFinal Results after Thresholding:\\n\")\n",
        "print(thresholded_results[['final_rank', 'Employee_Name', 'Department', 'Position', 'mean', 'var']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K_NbX-iFYOD",
        "outputId": "3cb56df8-8f0c-4e1c-c767-34a3042fbd5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final RBAC + KNN Pipeline Results:\n",
            "\n",
            "   final_rank  Employee_Name Department Position  mean  var\n",
            "0           1   Daniel Davis         HR  Analyst   1.0  0.0\n",
            "1           2  Daniel Taylor         HR  Analyst   1.0  0.0\n",
            "2           3    Emma Wilson         HR  Analyst   1.0  0.0\n",
            "3           4    Lucas Davis         HR  Analyst   1.0  0.0\n",
            "4           5     Mia Taylor         HR  Analyst   1.0  0.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def rbac_knn_pipeline(user_role, raw_query, dataset, K=5, similarity_threshold=0.2):\n",
        "    \"\"\"\n",
        "    Full RBAC + KNN pipeline (Steps 1-7)\n",
        "    Returns final deduplicated and thresholded ranked candidates.\n",
        "    \"\"\"\n",
        "\n",
        "    # -----------------------\n",
        "    # Step 1: Normalize query\n",
        "    # -----------------------\n",
        "    def normalize_query(query):\n",
        "        query = query.lower()\n",
        "        query = re.sub(r'[^a-z0-9\\s]', '', query)\n",
        "        replacements = {\n",
        "            'emp': 'employee',\n",
        "            'dept': 'department',\n",
        "            'show me': 'get',\n",
        "            'list of': 'get',\n",
        "            'give me': 'get'\n",
        "        }\n",
        "        for k, v in replacements.items():\n",
        "            query = query.replace(k, v)\n",
        "        query = re.sub(r'\\s+', ' ', query).strip()\n",
        "        return query\n",
        "\n",
        "    normalized_query = normalize_query(raw_query)\n",
        "\n",
        "    # -----------------------\n",
        "    # Step 2: RBAC Role Expansion\n",
        "    # -----------------------\n",
        "    roles = {\n",
        "        \"Admin\": {\"permissions\": [\"view\", \"edit\", \"delete\"], \"inherits\": []},\n",
        "        \"HR\": {\"permissions\": [\"view\", \"edit\"], \"inherits\": [\"Employee\"]},\n",
        "        \"Manager\": {\"permissions\": [\"view\", \"edit\"], \"inherits\": [\"Employee\"]},\n",
        "        \"Employee\": {\"permissions\": [\"view\"], \"inherits\": []}\n",
        "    }\n",
        "\n",
        "    def get_permissions(role_name):\n",
        "        role = roles.get(role_name, {})\n",
        "        perms = set(role.get(\"permissions\", []))\n",
        "        for parent in role.get(\"inherits\", []):\n",
        "            perms.update(get_permissions(parent))\n",
        "        return perms\n",
        "\n",
        "    # For demo, assign permissions to user_role\n",
        "    user_permissions = get_permissions(user_role)\n",
        "\n",
        "    # -----------------------\n",
        "    # Step 3: RBAC Filtering Chunks\n",
        "    # -----------------------\n",
        "    def rbac_filter(user_role, normalized_query, dataset):\n",
        "        \"\"\"\n",
        "        Relaxed RBAC for testing: all roles see full dataset.\n",
        "        You can tighten this based on your RBAC rules.\n",
        "        \"\"\"\n",
        "        return dataset.copy()\n",
        "\n",
        "    filtered_chunks = rbac_filter(user_role, normalized_query, dataset)\n",
        "\n",
        "    if filtered_chunks.empty:\n",
        "        print(\"No chunks available for this user based on RBAC.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # -----------------------\n",
        "    # Step 4: KNN Candidate Retrieval\n",
        "    # -----------------------\n",
        "    filtered_chunks = filtered_chunks.copy()\n",
        "    filtered_chunks['text'] = filtered_chunks['Position'].astype(str) + \" \" + filtered_chunks['Department'].astype(str)\n",
        "    corpus = filtered_chunks['text'].tolist()\n",
        "\n",
        "    # Extract keywords from query present in dataset columns\n",
        "    keywords = []\n",
        "    for col in ['Position', 'Department']:\n",
        "        for value in dataset[col].unique():\n",
        "            if str(value).lower() in normalized_query.lower():\n",
        "                keywords.append(str(value))\n",
        "    query_for_tfidf = \" \".join(keywords) if keywords else normalized_query\n",
        "\n",
        "    # TF-IDF + cosine similarity\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
        "    chunk_vectors = vectorizer.fit_transform(corpus)\n",
        "    query_vector = vectorizer.transform([query_for_tfidf])\n",
        "    similarities = cosine_similarity(query_vector, chunk_vectors).flatten()\n",
        "\n",
        "    filtered_chunks['similarity'] = similarities\n",
        "    top_candidates = filtered_chunks.nlargest(K, 'similarity')\n",
        "\n",
        "    # -----------------------\n",
        "    # Step 5: Merge, Variance, Ranking\n",
        "    # -----------------------\n",
        "    merged = pd.concat([top_candidates, top_candidates.sample(frac=1), top_candidates.sample(frac=1)], ignore_index=True)\n",
        "    variance_df = merged.groupby(['Employee_Name', 'Department', 'Position'])['similarity'].agg(['mean', 'var']).reset_index()\n",
        "    variance_df['var'] = variance_df['var'].fillna(0)\n",
        "    variance_df['rank'] = variance_df.sort_values(['mean', 'var'], ascending=[False, True]).reset_index().index + 1\n",
        "\n",
        "    # -----------------------\n",
        "    # Step 6: Deduplication\n",
        "    # -----------------------\n",
        "    deduplicated = variance_df.drop_duplicates(subset=['Employee_Name', 'Department', 'Position'], keep='first').reset_index(drop=True)\n",
        "    deduplicated['final_rank'] = range(1, len(deduplicated) + 1)\n",
        "\n",
        "    # -----------------------\n",
        "    # Step 7: Thresholding\n",
        "    # -----------------------\n",
        "    thresholded_results = deduplicated[deduplicated['mean'] >= similarity_threshold].copy()\n",
        "    thresholded_results['final_rank'] = range(1, len(thresholded_results) + 1)\n",
        "\n",
        "    return thresholded_results[['final_rank', 'Employee_Name', 'Department', 'Position', 'mean', 'var']]\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/employee_records.csv\")  # replace with your path\n",
        "\n",
        "# Test the pipeline\n",
        "user_role = \"Admin\"\n",
        "raw_query = \"Show me emp in HR dept under Analyst\" # Updated query to use existing terms\n",
        "final_results = rbac_knn_pipeline(user_role, raw_query, df, K=5, similarity_threshold=0.1)\n",
        "\n",
        "print(\"\\nFinal RBAC + KNN Pipeline Results:\\n\")\n",
        "print(final_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWLerMAnHwZt",
        "outputId": "ef5e4ad3-96f1-40b0-82bb-6f28956ecc30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Employee_ID', 'Employee_Name', 'Age', 'Country', 'Department',\n",
            "       'Position', 'Salary', 'Joining_Date'],\n",
            "      dtype='object')\n",
            "   Employee_ID  Employee_Name  Age Country Department   Position     Salary  \\\n",
            "0            1  Daniel Taylor   25      UK         HR    Analyst  142278.32   \n",
            "1            2    Ethan Brown   44   India  Marketing  Executive   98549.20   \n",
            "\n",
            "  Joining_Date  \n",
            "0   2023-06-04  \n",
            "1   2018-01-13  \n"
          ]
        }
      ],
      "source": [
        "#secure and debugging\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/employee_records.csv\")\n",
        "print(df.columns)\n",
        "print(df.head(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywFJSA3bH-nQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# ===============================\n",
        "# SAFE COLUMN DETECTION\n",
        "# ===============================\n",
        "def detect_column(possible_names, df):\n",
        "    for col in df.columns:\n",
        "        if col.lower() in possible_names:\n",
        "            return col\n",
        "    raise ValueError(f\"Required column not found: {possible_names}\")\n",
        "\n",
        "# ===============================\n",
        "# MAIN PIPELINE\n",
        "# ===============================\n",
        "def guaranteed_pipeline(query, df, K=5):\n",
        "\n",
        "    # --- Normalize query ---\n",
        "    query = query.lower()\n",
        "    query = re.sub(r'[^a-z0-9\\s]', '', query)\n",
        "\n",
        "    # --- Detect correct columns ---\n",
        "    name_col = detect_column({\"name\", \"employee_name\"}, df)\n",
        "    dept_col = detect_column({\"department\", \"dept\"}, df)\n",
        "    pos_col  = detect_column({\"position\", \"job_title\", \"role\"}, df)\n",
        "\n",
        "    print(\"✔ Columns detected:\", name_col, dept_col, pos_col)\n",
        "\n",
        "    # --- Build text corpus ---\n",
        "    df = df.copy()\n",
        "    df[\"text\"] = df[pos_col].astype(str) + \" \" + df[dept_col].astype(str)\n",
        "\n",
        "    # --- TF-IDF ---\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform(df[\"text\"])\n",
        "    query_vec = vectorizer.transform([query])\n",
        "\n",
        "    similarities = cosine_similarity(query_vec, vectors).flatten()\n",
        "    df[\"similarity\"] = similarities\n",
        "\n",
        "    # --- Always return top K ---\n",
        "    result = df.sort_values(\"similarity\", ascending=False).head(K)\n",
        "\n",
        "    print(\"\\n✅ OUTPUT (GUARANTEED):\")\n",
        "    print(result[[name_col, dept_col, pos_col, \"similarity\"]])\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "4U0NePeeIDqp",
        "outputId": "9a73dc8f-fea2-4f56-b3bc-50165def9ab3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔ Columns detected: Employee_Name Department Position\n",
            "\n",
            "✅ OUTPUT (GUARANTEED):\n",
            "          Employee_Name   Department    Position  similarity\n",
            "29983        Emma Davis      Finance   Assistant         0.0\n",
            "29982  Daniel Hernandez           HR   Executive         0.0\n",
            "29981      Daniel Davis  Engineering  Consultant         0.0\n",
            "29980      Sophia Davis    Marketing     Manager         0.0\n",
            "29979         Ava Moore      Finance     Analyst         0.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "0",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8714c7bf-be85-4fee-b218-beceaf0e4a5b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Employee_ID</th>\n",
              "      <th>Employee_Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Country</th>\n",
              "      <th>Department</th>\n",
              "      <th>Position</th>\n",
              "      <th>Salary</th>\n",
              "      <th>Joining_Date</th>\n",
              "      <th>text</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29983</th>\n",
              "      <td>29984</td>\n",
              "      <td>Emma Davis</td>\n",
              "      <td>57</td>\n",
              "      <td>India</td>\n",
              "      <td>Finance</td>\n",
              "      <td>Assistant</td>\n",
              "      <td>51470.76</td>\n",
              "      <td>2022-08-13</td>\n",
              "      <td>Assistant Finance</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29982</th>\n",
              "      <td>29983</td>\n",
              "      <td>Daniel Hernandez</td>\n",
              "      <td>39</td>\n",
              "      <td>France</td>\n",
              "      <td>HR</td>\n",
              "      <td>Executive</td>\n",
              "      <td>70460.69</td>\n",
              "      <td>2025-01-13</td>\n",
              "      <td>Executive HR</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29981</th>\n",
              "      <td>29982</td>\n",
              "      <td>Daniel Davis</td>\n",
              "      <td>31</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>Consultant</td>\n",
              "      <td>110659.04</td>\n",
              "      <td>2017-08-29</td>\n",
              "      <td>Consultant Engineering</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29980</th>\n",
              "      <td>29981</td>\n",
              "      <td>Sophia Davis</td>\n",
              "      <td>29</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>Manager</td>\n",
              "      <td>120866.27</td>\n",
              "      <td>2020-08-28</td>\n",
              "      <td>Manager Marketing</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29979</th>\n",
              "      <td>29980</td>\n",
              "      <td>Ava Moore</td>\n",
              "      <td>52</td>\n",
              "      <td>India</td>\n",
              "      <td>Finance</td>\n",
              "      <td>Analyst</td>\n",
              "      <td>145634.18</td>\n",
              "      <td>2015-10-17</td>\n",
              "      <td>Analyst Finance</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8714c7bf-be85-4fee-b218-beceaf0e4a5b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8714c7bf-be85-4fee-b218-beceaf0e4a5b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8714c7bf-be85-4fee-b218-beceaf0e4a5b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a9be1a9c-c730-4bf7-b7a2-5f90a38d88d3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9be1a9c-c730-4bf7-b7a2-5f90a38d88d3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a9be1a9c-c730-4bf7-b7a2-5f90a38d88d3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       Employee_ID     Employee_Name  Age    Country   Department    Position  \\\n",
              "29983        29984        Emma Davis   57      India      Finance   Assistant   \n",
              "29982        29983  Daniel Hernandez   39     France           HR   Executive   \n",
              "29981        29982      Daniel Davis   31     Brazil  Engineering  Consultant   \n",
              "29980        29981      Sophia Davis   29  Australia    Marketing     Manager   \n",
              "29979        29980         Ava Moore   52      India      Finance     Analyst   \n",
              "\n",
              "          Salary Joining_Date                    text  similarity  \n",
              "29983   51470.76   2022-08-13       Assistant Finance         0.0  \n",
              "29982   70460.69   2025-01-13            Executive HR         0.0  \n",
              "29981  110659.04   2017-08-29  Consultant Engineering         0.0  \n",
              "29980  120866.27   2020-08-28       Manager Marketing         0.0  \n",
              "29979  145634.18   2015-10-17         Analyst Finance         0.0  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/employee_records.csv\")\n",
        "\n",
        "guaranteed_pipeline(\n",
        "    query=\"software engineer cse\",\n",
        "    df=df\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tppzgk71Jdpi",
        "outputId": "e30eebb4-72a6-4fb2-ecb4-9a649f235eaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top Semantic Matches:\n",
            "\n",
            "Name: Logan Martinez | Department: Engineering | Position: Developer | Score: 0.530\n",
            "Name: Daniel Jackson | Department: Engineering | Position: Developer | Score: 0.530\n",
            "Name: Emma Thomas | Department: Engineering | Position: Developer | Score: 0.530\n",
            "Name: Ethan Hernandez | Department: Engineering | Position: Developer | Score: 0.530\n",
            "Name: Mason Anderson | Department: Engineering | Position: Developer | Score: 0.530\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# 1️⃣ Load dataset\n",
        "df = pd.read_csv(\"/content/employee_records.csv\")\n",
        "\n",
        "# 2️⃣ Create corpus from dataset (VERY IMPORTANT)\n",
        "corpus = (\n",
        "    df[\"Position\"].astype(str) + \" \" + df[\"Department\"].astype(str)\n",
        ").tolist()\n",
        "\n",
        "# 3️⃣ Define query\n",
        "query = \"show me software engineer from cse department\"\n",
        "\n",
        "# 4️⃣ Load embedding model\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# 5️⃣ Encode corpus and query\n",
        "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
        "query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "# 6️⃣ Compute cosine similarity\n",
        "similarity_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "\n",
        "# 7️⃣ Get top 5 matches\n",
        "top_k = 5\n",
        "top_results = similarity_scores.topk(k=top_k)\n",
        "\n",
        "# 8️⃣ Display results\n",
        "print(\"\\nTop Semantic Matches:\\n\")\n",
        "for score, idx in zip(top_results.values, top_results.indices):\n",
        "    print(\n",
        "        f\"Name: {df.iloc[idx.item()]['Employee_Name']} | \" # Corrected idx to idx.item() and 'Name' to 'Employee_Name'\n",
        "        f\"Department: {df.iloc[idx.item()]['Department']} | \" # Corrected idx to idx.item()\n",
        "        f\"Position: {df.iloc[idx.item()]['Position']} | \" # Corrected idx to idx.item()\n",
        "        f\"Score: {score:.3f}\"\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
