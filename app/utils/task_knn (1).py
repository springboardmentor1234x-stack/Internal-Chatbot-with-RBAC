# -*- coding: utf-8 -*-
"""Task_KNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h14Kp8GCwhMWCr6Fu0F7jZqM7gEZup4u
"""

import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# 1. Load the quarterly financial report
with open("/content/drive/MyDrive/quarterly_financial_report.md", "r", encoding="utf-8") as f:
    full_text = f.read()

# 2. Create 10 text chunks (simple split by blank lines)
raw_chunks = full_text.split("\n\n")
chunks = raw_chunks[:10]   # mini dataset of 10 chunks

print(f"Number of chunks: {len(chunks)}")
for i, c in enumerate(chunks):
    print(f"\n--- CHUNK {i} ---\n{c[:200]}...")  # preview first 200 chars

# 3. Fit TF-IDF vectorizer on the 10 chunks
vectorizer = TfidfVectorizer()
embeddings = vectorizer.fit_transform(chunks).toarray()

print("Embeddings shape:", embeddings.shape)  # (10, vocab_size)

def knn_search(query, embeddings, k):
    """
    Custom KNN over text chunks using cosine similarity.

    query: text query (string)
    embeddings: np.array of shape (num_chunks, dim)
    k: number of neighbors to return
    """
    # Embed the query using same TF-IDF vectorizer
    q_vec = vectorizer.transform([query]).toarray()

    # Compute cosine similarity between query and all chunks
    sims = cosine_similarity(q_vec, embeddings)[0]  # shape: (num_chunks,)

    # Sort indices by similarity (descending) and take top-k
    idx_sorted = np.argsort(-sims)[:k]

    # Return list of (index, similarity)
    return [(int(i), float(sims[i])) for i in idx_sorted]

# 4. Define queries
queries = [
    "Q1 revenue and net income",
    "cash flow from operations",
    "marketing spend and vendor costs"
]

# 5. Evaluate for different K values
k_values = [1, 3, 5]
results = {}

for k in k_values:
    results[k] = {}
    for q in queries:
        neighbors = knn_search(q, embeddings, k)
        results[k][q] = neighbors

# 6. Print results nicely
for k in k_values:
    print(f"\n===== K = {k} =====")
    for q in queries:
        print(f"\nQuery: {q}")
        for idx, sim in results[k][q]:
            print(f"  Chunk {idx} | similarity = {sim:.4f}")
            # optional: show snippet of the chunk
            print("   Text:", chunks[idx][:150].replace("\n", " "), "...")

# 7. Simple comparison: how many zero-similarity neighbors for each K
for k in k_values:
    zero_count = 0
    total_neighbors = 0
    for q in queries:
        for idx, sim in results[k][q]:
            total_neighbors += 1
            if sim == 0.0:
                zero_count += 1
    print(f"K = {k}: zero-sim neighbors {zero_count}/{total_neighbors}")