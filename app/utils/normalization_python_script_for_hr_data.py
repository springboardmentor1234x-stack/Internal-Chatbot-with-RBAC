# -*- coding: utf-8 -*-
"""normalization python script for HR data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12tZAYU6NnGuiPsG5jLKhl2gu-XXmw-QL
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# --- 1. Load the Data ---
# Assuming the file 'hr_data.csv' is in the current directory
df = pd.read_csv('/content/drive/MyDrive/hr_data.csv')
print("Original DataFrame Info:")
df.info()
print("-" * 30)

# --- 2. Data Type Normalization/Cleaning ---
# Convert date columns to datetime objects
date_columns = ['date_of_birth', 'date_of_joining', 'last_review_date']
for col in date_columns:
    df[col] = pd.to_datetime(df[col])
print("After Date Conversion (Info):")
df.info()
print("-" * 30)

# --- 3. Feature Scaling (Min-Max Normalization) ---
# Select the 'salary' column for normalization
salary_data = df[['salary']]

# Initialize the MinMaxScaler
# Min-Max scaling transforms data to a given range, typically [0, 1].
# Formula: X_normalized = (X - X_min) / (X_max - X_min)
scaler = MinMaxScaler()

# Fit the scaler to the salary data and transform the data
df['salary_normalized'] = scaler.fit_transform(salary_data)

# --- 4. Verification ---
print("Head of DataFrame after Normalization:")
# Display the original salary and the new normalized column
print(df[['salary', 'salary_normalized']].head())
print(f"\nMin of Normalized Salary: {df['salary_normalized'].min():.2f}")
print(f"Max of Normalized Salary: {df['salary_normalized'].max():.2f}")

import pandas as pd
import json

# --- 1. Load the Data ---
df = pd.read_csv('/content/drive/MyDrive/hr_data.csv')

# --- 2. Define the Chunking Strategy (Grouping by 'department') ---
chunk_groups = df.groupby('department')

# Dictionary to hold the generated metadata
metadata_records = {}
chunk_count = 0

# --- 3. Generate Chunks and Metadata for the first three ---
for department_name, chunk_data in chunk_groups:
    if chunk_count >= 3:
        # Stop after processing the first three chunks
        break

    # Calculate required metrics for metadata
    record_count = len(chunk_data)
    average_salary = chunk_data['salary'].mean()

    # --- 4. Define the Metadata Structure ---
    metadata = {
        "chunk_id": f"chunk_{chunk_count + 1}",
        "source_file": "hr_data.csv",
        "chunk_key": "department",
        "department_name": department_name,
        "record_count": record_count,
        "average_salary_usd": round(average_salary, 2),
        "columns_in_chunk": list(chunk_data.columns)
    }

    # Store the metadata
    metadata_records[f"Chunk {chunk_count + 1}"] = metadata

    chunk_count += 1

{
    "Chunk 1": {
        "chunk_id": "chunk_1",
        "source_file": "hr_data.csv",
        "chunk_key": "department",
        "department_name": "Business",
        "record_count": 6,
        "average_salary_usd": 1420026.61,
        "columns_in_chunk": [
            "employee_id",
            "full_name",
            "role",
            "department",
            "email",
            "location",
            "date_of_birth",
            "date_of_joining",
            "manager_id",
            "salary",
            "leave_balance",
            "leaves_taken",
            "attendance_pct",
            "performance_rating",
            "last_review_date"
        ]
    },
    "Chunk 2": {
        "chunk_id": "chunk_2",
        "source_file": "hr_data.csv",
        "chunk_key": "department",
        "department_name": "Compliance",
        "record_count": 5,
        "average_salary_usd": 963683.85,
        "columns_in_chunk": [
            "employee_id",
            "full_name",
            "role",
            "department",
            "email",
            "location",
            "date_of_birth",
            "date_of_joining",
            "manager_id",
            "salary",
            "leave_balance",
            "leaves_taken",
            "attendance_pct",
            "performance_rating",
            "last_review_date"
        ]
    },
    "Chunk 3": {
        "chunk_id": "chunk_3",
        "source_file": "hr_data.csv",
        "chunk_key": "department",
        "department_name": "Data",
        "record_count": 8,
        "average_salary_usd": 1218149.16,
        "columns_in_chunk": [
            "employee_id",
            "full_name",
            "role",
            "department",
            "email",
            "location",
            "date_of_birth",
            "date_of_joining",
            "manager_id",
            "salary",
            "leave_balance",
            "leaves_taken",
            "attendance_pct",
            "performance_rating",
            "last_review_date"
        ]
    }
}